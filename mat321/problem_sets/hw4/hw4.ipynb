{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAT 321 - PS4\n",
    "\n",
    "* You can (and probably should) discuss assignments with each others, and the course staff, but you must write and understand any solutions/code that you submit. You can consult any resource you want for this homework, but you should cite sources you used.\n",
    "* You must upload the assignment to Gradescope before the deadline. You should submit this notebook in .ipynb format, and optinally a single PDF file with your written answers. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Diagonalization of Circulant Matrices\n",
    "\n",
    "\n",
    "In these problem sets, we have used repeatedly that circulant matrices are diagonalized by the DFT to:\n",
    "* derive fast mat-vecs with circulant and Toeplitz matrices\n",
    "* derive fast solvers for circulant and perturbed circulant systems\n",
    "* deblur large datasets of images\n",
    "\n",
    "That is, we used the fact that:\n",
    "\n",
    "$$C = F^{-1} \\Lambda F $$\n",
    "\n",
    "where $F$ is the DFT matrix, and $\\text{diag}(\\Lambda) = Fc$. The goal of this exercise is to prove this identity.\n",
    "\n",
    "Note that this is an eigendecomposition of $C$, where $V = F^{-1}$ is the matrix of eigenvectors. Recall that the DFT matrix is \n",
    "\n",
    "$$\n",
    "F = \\frac{1}{\\sqrt{n}} \\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 & \\cdots & 1    \\\\\n",
    "1 & \\omega & \\omega^2 &  \\omega^3 & \\cdots & \\omega^{n-1}    \\\\\n",
    "1 & \\omega^2 & \\omega^4 &  \\omega^6 & \\cdots & \\omega^{2(n-1)}    \\\\\n",
    "1 & \\omega^3 & \\omega^6 &  \\omega^9 & \\cdots & \\omega^{2(n-1)}    \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots  & \\ddots & \\ddots   \\\\\n",
    "1 & \\omega^{n-1} & \\omega^{2(n-1)} & \\omega^{3(n-1)}  & \\cdots & \\omega^{(n-1)(n-1)}    \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\omega = \\exp(- \\imath 2 \\pi / n) $, $\\imath^2 = -1$ (note that $\\omega$ depends on $n$).\n",
    "Also recall that $F$ with this normalization is unitary, that is $F^{-1} = F^* = \\bar{F}^T$, and $F$ is symmetric (but *not hermitian*), so  $F^{-1} = \\bar{F}$.\n",
    "\n",
    "We prove this identity in 3 steps:\n",
    "\n",
    "1. Let $D_n \\in \\mathbb{R}^{n \\times n}$ be the circulant downward shift matrix. For $n = 5$, this matrix is:\n",
    "\n",
    "$$\n",
    "D_5 = \\begin{bmatrix}\n",
    " & & & & 1 \\\\\n",
    "1 & & & & \\\\\n",
    " & 1& & & \\\\\n",
    " & & 1& & \\\\\n",
    " & & & 1& \\\\\n",
    "\\end{bmatrix}\n",
    "$$. \n",
    "We will first show that the DFT diagonalizes $D_n$: $D_n = F^{-1} \\Gamma F $ for some diagonal matrix $\\Gamma$. Here's how to proceed:\n",
    "\n",
    " - Show that $D_n {F}_{i+1} = \\gamma_{i+1} {F}_{i+1} $ where ${F}_{i+1}$ is the $i+1$ column of ${F}$:\n",
    "\n",
    "$$\n",
    "F_{i+1} = \\frac{1}{\\sqrt{n}}  \\begin{bmatrix}\n",
    "1    \\\\\n",
    "{\\omega}^{i}\\\\\n",
    "{\\omega}^{2i}\\\\\n",
    "{\\omega}^{3i}\\\\\n",
    "\\vdots \\\\\n",
    "{\\omega}^{(n-1)i}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and $\\gamma_{i+1} = \\bar{\\omega}^i$. \n",
    "- Argue that this implies $D_n F = F \\bar{\\Gamma} $, where $\\bar{\\Gamma}$ is a diagonal matrix with diagonal entries $\\gamma_i$. \n",
    "- Take the complex conjugate of previous part, and conclude that  $D_n = F^{-1} \\Gamma F$ \n",
    "\n",
    "2. Write any circulant matrix as an $(n-1)$ degree polynomial in $D_n$. That is, find the coefficients $\\alpha_k$ so that:\n",
    "\n",
    "$$C = \\sum_{k=0}^{n-1} \\alpha_k D_n^k $$\n",
    "\n",
    "Recall that $D_n^0$ is defined as the identity. You can do this by inspection.\n",
    "\n",
    "3. Use the previous two parts to show $C = F^{-1} \\Lambda F $ for some diagonal matrix $\\Lambda$. Some inspection reveals that $\\text{diag}(\\Lambda) = Fc$, but you do not need to prove this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your answer to Q1 here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 The Bartels-Stewart algorithm\n",
    "In this problem, we derive an algorithm for solving a special kind of matrix equation: Sylvester equations. \n",
    "A Sylvester equation is of the form:\n",
    "$$\n",
    "AX - XB = F\n",
    "$$\n",
    "where $A,X,B,F \\in \\mathbb{R}^{n \\times n}$.\n",
    "Using the Kronecker formalism from HW3, we can solve this matrix equation in $\\mathcal{O}(n^6)$, but we can do better: the Bartels-Stewart algorithm is an algorithm that solves this equation in $\\mathcal{O}(n^3)$.\n",
    "The Bartels-Stewart algorithm is based on one clever observation: if $A$ and $B$ are diagonal matrices, then this equation is easy to solve. Say $A = \\text{diag}(d)$, $B = \\text{diag}(p)$, then the $(i,j)$-th entry of the Sylvester equation reads:\n",
    "$$ d_i x_{i,j} - x_{i,j} p_j = f_{i,j} $$\n",
    "i.e., the system is uncoupled and $x_{i,j}$  can be easily found as:\n",
    "$$\n",
    "x_{i,j} = \\frac{f_{i,j}}{d_i - p_j} \\ .\n",
    "$$\n",
    "From this equation, it is clear that there is a unique solution if and only if $d_i - p_j \\neq 0 \\leftrightarrow d_i \\neq p_j$ for all $i,j$.\n",
    "\n",
    "\n",
    "To solve a general Sylvester equation, Bartels-Stewart reduces a general Sylvester equation to the diagonal case using an eigenvalue decomposition.\n",
    "\n",
    "\n",
    "\n",
    "## 2.1\n",
    "Assume $A$ and $B$ are diagonalizable, that their eigenvalues decompositions are\n",
    "$$ \n",
    "A = U \\Sigma U^{-1}, \\qquad B = V\\Lambda V^{-1}, \n",
    "$$\n",
    "and that $X$ satisfies the Sylvester equation $AX - XB = F$.\n",
    "Show that the matrix $\\hat{X} = U^{-1} X V $ satisfies the following transformed (diagonal) Sylvester equation:\n",
    "\n",
    "$$ \\Sigma \\hat{X}- \\hat{X} \\Lambda  = \\hat{F} $$\n",
    "\n",
    "for some matrix $\\hat{F} $. \n",
    "\n",
    "\n",
    "\n",
    "<!-- # 1.2 \n",
    "Assume A and B are diagonalizable as above. Using your answer above, and using the Kronecker formalism, write conditions under which a Sylvester equation has a unique solution. -->\n",
    "\n",
    "## 2.2\n",
    "Use the previous part to show that if $A$ is symmetric positive definite, and $B$ is symmetric negative definite (i.e. $C := -B$ is symmetric positive definitive), then the Sylvester equation has a unique solution. \n",
    "\n",
    "## 2.3 \n",
    "Use 1.1 to design and implement an $\\mathcal{O}(n^3)$ solver for a general Sylvester equation. You may assume that the matrices are diagonalizable but not SPD. \n",
    "\n",
    "\n",
    "You may use `np.linalg.eig()` which computes an eigenvalue decomposition of $A$ in $\\mathcal{O}(n^3)$.\n",
    "\n",
    "Reminder: the [number one sin of Numerical Linear Algebra](https://nhigham.com/2022/10/11/seven-sins-of-numerical-linear-algebra/) is to form the inverse of a matrix. In particular, these two commands should be avoided like the plague: `np.linalg.inv(A)` or `np.linalg.solve(A,I)` (they do the same computation). Instead, you should use:\n",
    "`np.linalg.solve(A,F)` to compute $X = A^{-1} F$ and `np.linalg.solve(A.T,F.T).T`  to compute $X = F A^{-1} = ({A^{-1}}^T {F}^T)^T$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your answer to parts 1 and 2 here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Bartels_Stewart(A,B,F):\n",
    "    ## ADD YOUR CODE HERE\n",
    "    X = np.zeros_like(F)\n",
    "    return X\n",
    "\n",
    "\n",
    "# THIS CODE IS WRITTEN FOR YOU. NO NEED TO CHANGE IT\n",
    "n = 10\n",
    "A = np.random.randn(n,n)\n",
    "B = np.random.randn(n,n)\n",
    "X = np.random.randn(n,n)\n",
    "\n",
    "F = A@X - X@(B)\n",
    "\n",
    "Xsolve = Bartels_Stewart(A, B, F)\n",
    "\n",
    "# Should be close to machine epsilon ~1e-14 is fine\n",
    "print('error: ', np.linalg.norm(Xsolve - X )/np.linalg.norm(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Fast PDE Solver: Poisson's Equation\n",
    "\n",
    "In HW2, we derived a numerical scheme to solve Poisson's equation in 1D:\n",
    "\n",
    "$$\n",
    "- \\frac{d^2}{dx^2} u(x) = f(x), \\quad u(0) = u(1) = 0.\n",
    "$$\n",
    "\n",
    "The discretized system takes the form:\n",
    "\n",
    "$$\n",
    "T u = h^2 f,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "T = \\begin{bmatrix}\n",
    "2 & -1 & & & \\\\\n",
    "-1 & 2 & -1 & & \\\\\n",
    "& -1 & 2 & -1 & \\\\\n",
    "& & \\ddots & \\ddots & \\ddots \\\\\n",
    "& & & -1 & 2 \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "f = \\begin{bmatrix}\n",
    "f(h) \\\\\n",
    "f(2h) \\\\\n",
    "\\vdots \\\\\n",
    "f(nh) \\\\\n",
    "\\end{bmatrix}, \n",
    "$$\n",
    "\n",
    "and $ h = \\frac{1}{n+1} $. Since $ T \\in \\mathbb{R}^{n \\times n} $ is tridiagonal, we can solve this system in $ O(n) $ operations using a banded LU. All variations of the 1D problem are similarly straightforward.\n",
    "\n",
    "The 2D case is more interesting. Consider Poisson's equation on the unit square with homogeneous Dirichlet boundary conditions:\n",
    "\n",
    "$$\n",
    "- \\frac{d^2}{dx^2} u(x,y) - \\frac{d^2}{dy^2} u(x,y) = f(x,y), \\\\\n",
    "u(x,0) = u(x,1) = 0, \\\\\n",
    "u(0,y) = u(1,y) = 0.\n",
    "$$\n",
    "\n",
    "Poisson's in 2D and 3D equation models diffusion processes, with applications in fluid flow, heat transfer, and chemical transport. It also serves as a foundational problem for more complex equations.\n",
    "\n",
    "We discretize the equation on an $ n \\times n $ uniform grid $ (x_i, y_j) $, where $ x_i = ih $, $ y_j = jh $, and $ h = \\frac{1}{n+1} $. Let $ F_{i,j} = h^2 f(x_i, y_j) $; that is, the entry $ (i,j) $ of matrix $ F \\in \\mathbb{R}^{n \\times n} $ is $ h^2 $ times the value of $ f $ at $ (x_i, y_j) $. We seek approximate values $ U_{i,j} \\approx u(x_i, y_j) $ using finite differences.\n",
    "\n",
    "The operator $ u \\rightarrow - \\frac{d^2}{dx^2} u $ with boundary conditions $ u(x,0) = u(x,1) = 0 $ can be applied independently to the columns of $ U $, resulting in $ U \\rightarrow TU $. Similarly, the operator $ u \\rightarrow - \\frac{d^2}{dy^2} u $ with boundary conditions $ u(0,y) = u(1,y) = 0 $ can be applied independently to the rows of $ U $, yielding $ U \\rightarrow UT^T = UT $.\n",
    "\n",
    "Therefore, the discretized operator becomes $ U \\rightarrow TU + UT $, leading to the matrix equation:\n",
    "\n",
    "$$\n",
    "TU + UT = F.\n",
    "$$\n",
    "\n",
    "Our goal is to solve this linear system for $ U $. Using the Kronecker formalism from the previous homework, we could solve this in $ O(n^6) $ operations—not ideal. The Bartels-Stewart algorithm improves this to $ O(n^3) $ complexity, but we can do even better.\n",
    "A key property of the second-order finite difference matrix $ T $ is that its eigenvalue decomposition can be computed analytically:\n",
    "\n",
    "$$\n",
    "T = S^{-1} \\Lambda S,\n",
    "$$\n",
    "\n",
    "where $ S $ is the Discrete Sine Transform (DST) matrix with components $ S_{kj} = \\sqrt{\\tfrac{2}{n+1}} \\sin\\left(\\tfrac{kj\\pi}{n+1}\\right) $, and the eigenvalues are $ \\lambda_j = 4 \\sin^2 \\left( \\tfrac{j \\pi}{2(n+1)} \\right) $. The DST is the imaginary part of the Discrete Fourier Transform (DFT). Thanks to this connection, we can compute $ Sx $ in $ \\mathcal{O}(n \\log n) $ time using the Fast Fourier Transform (FFT), available via `scipy.fft.dst(x, type=1, norm=\"ortho\")`. The DST matrix is orthogonal and symmetric when properly normalized (`norm=\"ortho\"`), so $ S = S^T = S^{-1} $.\n",
    "\n",
    "Your task is to write a solver for Poisson's equation with $ \\mathcal{O}(n^2 \\log n) $ complexity using these properties of $ T $.\n",
    "\n",
    "**Programming Note:** To compute $ SX $ (where $ X $ is a matrix), use `scipy.fft.dst(X, type=1, norm=\"ortho\", axis=1)`. To compute $ XS$, use `scipy.fft.dst(X, type=1, norm=\"ortho\", axis=0)`. You can use the `dst(X, axis=0)` function defined below to keep the syntax nicer. A function which returns the eigenvalues of $T$ is also provided for you below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fft\n",
    "\n",
    "def fast_2d_poisson_solver(F):\n",
    "    # ADD YOUR CODE HERE\n",
    "    X = np.zeros_like(F)\n",
    "    return X\n",
    "\n",
    "## ALL THE CODE BELOW IS PROVIDED FOR YOU.\n",
    "\n",
    "# A helper function you can use if you want\n",
    "def dst(X,axis =0):\n",
    "    return scipy.fft.dst(X, type = 1, norm = \"ortho\", axis =axis)\n",
    "\n",
    "# Computes eigenvalues of the Tridiagonal matrix from known analytical formula\n",
    "def get_eigenvalues_of_T(n):\n",
    "    return 4 * (np.sin(np.arange(1,n+1) * np.pi / (2*( n + 1)))**2)\n",
    "\n",
    "# Get the matrix explicitely, useful for debugging\n",
    "def get_second_order_diff_matrix(n):\n",
    "    T = np.diag(2 * np.ones(n)) + np.diag(-1 *  np.ones(n-1), k = 1) + np.diag(-1 * np.ones(n-1) , k = -1)\n",
    "    return T\n",
    "\n",
    "### TEST FOR CORRECTNESS\n",
    "\n",
    "n = 100\n",
    "h = 1 / (n+1)\n",
    "from scipy.ndimage import gaussian_filter\n",
    "F = gaussian_filter(np.random.randn(n,n) * h**2 , 3) # An interesting looking RHS function f\n",
    "\n",
    "# O(n^3) way using your Bartles-Stewart code:\n",
    "T = get_second_order_diff_matrix(n)\n",
    "X = Bartels_Stewart(T, -T, F)\n",
    "print('Bartels-Stewart error (if this doesnt work, fix previous question!)',np.linalg.norm(T @X + X@T - F) / np.linalg.norm(F))\n",
    "\n",
    "# O(n^2 log(n)) way using your fast Poisson code:\n",
    "X2 = fast_2d_poisson_solver(F)\n",
    "print('Fast poisson solver error', np.linalg.norm(T @X2 + X2@T - F) / np.linalg.norm(F))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(F)\n",
    "plt.title(\"Right hand side function f(x,y)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X2)\n",
    "plt.title(\"Approximate solution u(x,y)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### TEST FOR COMPLEXITY\n",
    "\n",
    "### A scaling plot\n",
    "\n",
    "import time\n",
    "# Define the scaling experiment\n",
    "# This one takes 1s on my laptop\n",
    "sizes = [10, 20, 50, 100, 200, 300]  # Increase n gradually\n",
    "\n",
    "# If you think your method is right, uncomment this! It takes ~10s on my laptop\n",
    "# sizes = [10, 20, 50, 100, 200, 300, 500, 1000]  # Increase n gradually\n",
    "\n",
    "bartels_times = []\n",
    "fast_times = []\n",
    "\n",
    "for n in sizes:\n",
    "    h = 1 / (n + 1)\n",
    "    F = np.ones((n, n)) * h**2\n",
    "\n",
    "    # Time Bartels-Stewart solver\n",
    "    T = get_second_order_diff_matrix(n)\n",
    "    start = time.time()\n",
    "    X_bartels = Bartels_Stewart(T, -T, F)\n",
    "    bartels_times.append(time.time() - start)\n",
    "\n",
    "    # Time the fast Poisson solver\n",
    "    start = time.time()\n",
    "    X_fast = fast_2d_poisson_solver(F)\n",
    "    fast_times.append(time.time() - start)\n",
    "\n",
    "# Create reference lines for O(n^2) and O(n^3) scaling\n",
    "sizes_np = np.array(sizes)\n",
    "o_n2_ref = (sizes_np ** 2) * (fast_times[4] / sizes_np[4] ** 2)  # Normalized to first data point\n",
    "o_n3_ref = (sizes_np ** 3) * (bartels_times[4] / sizes_np[4] ** 3)  # Normalized to first data point\n",
    "\n",
    "# Plot the scaling results with reference lines\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sizes, bartels_times, label=\"Bartels-Stewart (O(n^3))\", marker=\"o\")\n",
    "plt.plot(sizes, fast_times, label=\"Fast Poisson Solver (O(n^2 log(n)))\", marker=\"o\")\n",
    "plt.plot(sizes, o_n2_ref, '--', label=\"O(n^2) Reference\", color='gray')\n",
    "plt.plot(sizes, o_n3_ref, '--', label=\"O(n^3) Reference\", color='black')\n",
    "\n",
    "# Add plot labels and formatting\n",
    "plt.xlabel(\"Matrix Size (n)\")\n",
    "plt.ylabel(\"Computation Time (seconds)\")\n",
    "plt.title(\"Scaling of 2D Poisson Solvers\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")  # Set x-axis to logarithmic scale\n",
    "plt.yscale(\"log\")  # Set y-axis to logarithmic scale\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Crafting the jewel \n",
    "\n",
    "We spent two weeks deriving one of the jewels of numerical linear algebra: the shifted-QR algorithm. Time to pull all the pieces together.\n",
    "When applied to real symmetric matrices, the algorithm looks as follows.\n",
    "\n",
    "\n",
    "> $Q_0 A^{(0)} Q_0 ^T = A \\qquad $  (1) (Compute a reduction to tridiagonal by Householder Reflection)\n",
    ">\n",
    "> $M \\leftarrow m$\n",
    ">\n",
    ">for $k = 1,2, \\dots$\n",
    ">\n",
    ">> $\\mu_k = A_{M,M}^{(k-1)} \\qquad $  (Compute Rayleigh quotient) \n",
    ">>\n",
    ">> $Q^{(k)}, R^{(k)} \\leftarrow A^{(k-1)} - \\mu_k I  \\qquad $  (2) (Compute QR decomposition of the shifted matrix) \n",
    ">>\n",
    ">> $A^{(k)}  \\leftarrow R^{(k)} Q^{(k)} +  \\mu_k I \\qquad $ (3) (Recombine factors) \n",
    ">>\n",
    ">> if $|A_{M,M-1}^{(k)} | < \\text{tol}$: $\\qquad  $  (4) (If converged to eigenvalue)\n",
    ">>>\n",
    ">>> Add $A_{M,M}^{(k)}$ to list of eigenvalues\n",
    ">>>\n",
    ">>> $A^{(k)} \\leftarrow A^{(k)}_{[1:M-1, 1:M-1]}  \\qquad $  (Deflate: ignore last row and column)\n",
    ">>>\n",
    ">>> $M \\leftarrow  M-1$\n",
    ">>> \n",
    ">> if $ M = 1: $   (The trivial 1x1 matrix case: the entry is the eigenvalue)\n",
    ">>> Add $A_{1,1}^{(k)}$ to list of eigenvalues\n",
    ">>>\n",
    ">>> terminate\n",
    ">\n",
    ">end while\n",
    "\n",
    "- Step (1) was implemented in precept 8 in $O(m^3)$\n",
    "\n",
    "- Step (2) was implemented in HW3 $O(m^2)$ for (nonsymmetric). Use your implementation from HW2 (or better yet, modify it to make it $O(m)$ for tridiagonal (optional)!).\n",
    "\n",
    "- Step (3) Step 3 is a matrix-matrix multiply which is $O(m^3)$ naively. However, it could be implemented in $O(m)$ since it is a matrix-matrix multiply between two very structured and sparse matrices (optional).\n",
    "\n",
    "- Step (4) is the deflation step. We check if we have converged to an eigenvalue.\n",
    "\n",
    "\n",
    "As a result of the shifting we recover the $O(\\epsilon^3)$ converge of the Rayleigh quotient iteration. Thus, we expect to need only a handful of iterations per eigenvalues (3-4). \n",
    "\n",
    "Your task is to implement the shifted-QR algorithm above and keep track of how many QR iterations you are doing. Make sure that you only need $< 4 n$ QR iterations to compute all eigenvalues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_QR_iteration(A, tol =1e-13):\n",
    "    eigenvalues = []\n",
    "    n_iters = 0 \n",
    "    ## ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "    while ():\n",
    "        ## You can replace this loop, with whatever you want, but make sure you keep track of the number of iterations \n",
    "        # (specifically, the number of QR decomposition you are computing)\n",
    "        n_iters +=1 \n",
    "\n",
    "    eigenvalues = np.zeros(A.shape[0])\n",
    "    return eigenvalues,  n_iters\n",
    "\n",
    "n = 100\n",
    "# A test case: a random symmetric matrix\n",
    "A = np.random.randn(n,n)\n",
    "A = A + A.T \n",
    "\n",
    "# Compute eigenvalues with built-in:\n",
    "eigvals1 = np.linalg.eigvals(A)\n",
    "\n",
    "# Compute with your code\n",
    "eigvals2, n_iters = shifted_QR_iteration(A.copy())\n",
    "\n",
    "# Check that the number eigenvalues are correct:\n",
    "print('eigenvalue error:', np.max(np.sort(eigvals1) - np.sort(eigvals2)))\n",
    "\n",
    "# Number of n_iters divided by n:\n",
    "# Should be < 4\n",
    "print('number of QR iterations per eigenvalues:', n_iters/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Spectral Embedding\n",
    "\n",
    "In this problem we explore nonlinear dimensionality reduction for high-dimensional data. Our goal is to represent a complex dataset using only one parameter. As a motivating example, consider a disordered sequence of images showing a rotating duck: each image lives in a high-dimensional pixel space, yet the underlying variation can be described by a single parameter (the rotation angle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load images from the spinning_duck directory in their existing order\n",
    "files = sorted(glob.glob(\"./spinning_duck/*.png\"))\n",
    "\n",
    "# Load the images as grayscale and stack them\n",
    "frames = np.stack([np.array(Image.open(f).convert(\"L\"), dtype=np.float64) for f in files])\n",
    "N, H, W = frames.shape\n",
    "print(f\"Loaded {N} images from './spinning_duck' with size {H}x{W}\")\n",
    "\n",
    "# Visualize a few frames to check\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for ax, idx in zip(axes, [0, N//5, 2*N//5, 3*N//5, 4*N//5, N-1]):\n",
    "    ax.imshow(frames[idx], cmap='gray')\n",
    "    ax.set_title(f'Frame {idx}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will construct a one-dimensional embedding for such data using the eigenvectors of a similarity matrix.\n",
    "\n",
    "Let $W$ be the similarity matrix, with entries\n",
    "\n",
    "$$\n",
    "w_{ij} = \\exp\\left(-\\frac{\\|y_i - y_j\\|_2^2}{2\\sigma^2}\\right),\n",
    "\\qquad y_i \\in \\mathbb{R}^{128^2}.\n",
    "$$\n",
    "where $\\{y_i\\}_{i=1}^{N}$ are images and $\\sigma$ is a fixed bandwidth parameter.\n",
    "\n",
    "The only assumptions we need to apply this dimensional reduction method is that the similarity matrix $W$ is symmetric with nonnegative entries; it need not come from a Gaussian kernel specifically.\n",
    "\n",
    "We wish to assign each image $y_i$ a scalar value $x_i \\in \\mathbb{R}$ such that similar images are mapped close together. To quantify this, define the embedding vector $x = (x_1, \\dots, x_N)$ and energy\n",
    "\n",
    "$$\n",
    "E(x) = \\sum_{i,j=1}^N w_{ij} (x_i - x_j)^2.\n",
    "$$\n",
    "\n",
    "Large weights $w_{ij}$ strongly penalize separating $x_i$ and $x_j$. Our task is to find $x$ that minimizes $E(x)$.\n",
    "\n",
    "### Part A\n",
    "\n",
    "Let $d = W\\mathbf{1}$, where $\\mathbf{1}$ is the all-ones vector, and define $D = \\mathrm{diag}(d)$.\n",
    "\n",
    "Find a matrix $L$ in terms of $W$ and $D$ such that\n",
    "\n",
    "$$\n",
    "E(x) = 2\\, x^\\top L x.\n",
    "$$\n",
    "\n",
    "Prove that $L$ is symmetric and positive semidefinite.\n",
    "\n",
    "### Part B\n",
    "\n",
    "The minimizer $x = \\alpha \\mathbf{1}$ (for any $\\alpha$) is useless — it maps all data points to the same location. Additionally, scaling $x$ shrinks $E(x)$ arbitrarily. To avoid this, we constrain the solution:\n",
    "\n",
    "$$\n",
    "\\min_{x \\in \\mathbb{R}^N} x^\\top L x\n",
    "\\qquad \\text{s.t.} \\qquad\n",
    "\\|x\\|_2 = 1, \\quad \\mathbf{1}^\\top x = 0.\n",
    "$$\n",
    "\n",
    "Introducing Lagrange multipliers gives the Lagrangian\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x,\\lambda,\\mu)\n",
    "= x^\\top L x\n",
    "- \\lambda (\\|x\\|_2^2 - 1)\n",
    "- \\mu (\\mathbf{1}^\\top x).\n",
    "$$\n",
    "\n",
    "Derive the first-order optimality conditions and show that any critical point satisfies\n",
    "\n",
    "$$\n",
    "Lx = \\lambda x, \\qquad \\mathbf{1}^\\top x = 0.\n",
    "$$\n",
    "\n",
    "### Part C\n",
    "\n",
    "Express the constrained minimizer in terms of the eigenvectors of $L$, assuming $L$ has a single zero eigenvalue (i.e., the nullspace of $L$ is spanned by $\\mathbf{1}$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write your answer in here \n",
    "\n",
    "## Part A\n",
    "\n",
    "## Part B\n",
    "\n",
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D (Implementation and Visualization)\n",
    "\n",
    "Implement your solution from Part C using the duck dataset. You may use `np.linalg.eig` or `scipy.linalg.eigh`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_embedding(W, D):\n",
    "    '''\n",
    "    Return the vector $x$ that minimizes $E(x)$ subject to the constraints.\n",
    "    The vector $x$ should have the same length as the number of frames\n",
    "    Input: \n",
    "        W: a numpy array of shape (N, N): the similarity matrix\n",
    "        D: a numpy array of shape (N, N): D = diag(d) where d is the sum of the rows of W\n",
    "    Output: \n",
    "        x: a numpy array of shape (N,)\n",
    "    '''\n",
    "    # Return the embedding vector $x$\n",
    "    embedding = np.zeros(W.shape[0])\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "## This code is provided for you. No need to change it!\n",
    "\n",
    "## Compute the similarity matrix $W$ and the diagonal matrix $D$ from the frames\n",
    "def compute_W_D_from_frames(frames):\n",
    "    N = frames.shape[0]\n",
    "    X = frames.reshape(N, -1)\n",
    "    sqn = np.sum(X * X, axis=1, keepdims=True)\n",
    "    dist2 = np.maximum(sqn + sqn.T - 2 * (X @ X.T), 0.0)\n",
    "    sigma = np.median(np.sqrt(dist2 + 1e-18)[~np.eye(N, dtype=bool)]) * 0.2\n",
    "    W = np.exp(-dist2 / (2 * sigma**2))\n",
    "    d = W.sum(axis=1)\n",
    "    D = np.diag(d)\n",
    "    return W, D\n",
    "\n",
    "\n",
    "def compute_energy_function_naive(x, W):\n",
    "    N = W.shape[0]\n",
    "    energy = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            energy += W[i, j] * (x[i] - x[j])**2\n",
    "    return energy\n",
    "\n",
    "\n",
    "W, D = compute_W_D_from_frames(frames)\n",
    "\n",
    "\n",
    "## A few tests for your code\n",
    "embedding = compute_spectral_embedding(W, D)\n",
    "\n",
    "# Is \\|x\\|_2 = 1?\n",
    "if not np.isclose(np.linalg.norm(embedding), 1):\n",
    "    print(\"Error: The norm of the embedding is not 1! Constraint is not satisfied!\")\n",
    "else:\n",
    "    print(\"The norm of the embedding is 1\")\n",
    "\n",
    "# Is \\mathbf{1}^\\top x = 0?\n",
    "if not np.isclose(np.sum(embedding), 0):\n",
    "    print(\"Error: The sum of the embedding is not 0! Constraint is not satisfied!\")\n",
    "else:\n",
    "    print(\"The sum of the embedding is 0\")\n",
    "\n",
    "\n",
    "if compute_energy_function_naive(embedding, W)  > 0.13:\n",
    "    print(\"Error: The energy function is too large! You are not at the minimum!\")\n",
    "else:\n",
    "    print(\"The energy function is small enough!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Reorder the frames according to the embedding\n",
    "sorted_indices = np.argsort(embedding)\n",
    "frames_ordered = frames[sorted_indices]\n",
    "\n",
    "#. Plot the sequence of images ordered by the embedding\n",
    "num_show = min(10, N)  # Show up to 10 images\n",
    "idxs = np.linspace(0, N-1, num_show, dtype=int)\n",
    "\n",
    "\n",
    "## Plot original ordering\n",
    "fig, axes = plt.subplots(1, num_show, figsize=(2*num_show, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(frames[idxs[i]], cmap='gray')\n",
    "    ax.set_title(f'Order {idxs[i]}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Duck images in original order')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## Plot ordered by spectral embedding\n",
    "#  It should look like a spinning duck!\n",
    "fig, axes = plt.subplots(1, num_show, figsize=(2*num_show, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(frames_ordered[idxs[i]], cmap='gray')\n",
    "    ax.set_title(f'Order {idxs[i]}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Duck images ordered by spectral embedding')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play_duck_movie(frames, interval=0.2, ordering = ''):\n",
    "    \"\"\"\n",
    "    Display a movie of the frames in order with the given interval between frames.\n",
    "    Also shows the frame number.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import time\n",
    "    from IPython.display import display, clear_output\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(frames[0], cmap='gray')\n",
    "    txt = ax.text(0.5, 1.05, f\"Frame 0\", color='black', fontsize=14, ha='center', va='bottom', transform=ax.transAxes)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        im.set_data(frame)\n",
    "        txt.set_text(f\"Frame {i} - {ordering}\")\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "        plt.pause(interval)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "# A movie of the images in the embedding order!\n",
    "play_duck_movie(frames, interval=0.2, ordering='Original ordering')\n",
    "play_duck_movie(frames_ordered, interval=0.2, ordering='Spectral embedding')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit papers:\n",
    "* Randomized algorithms - https://arxiv.org/pdf/2002.01387.pdf \n",
    "* Divide-and-conquer algorithms for eigenvalues - https://epubs.siam.org/doi/10.1137/S0895479892241287"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recovar_dev",
   "language": "python",
   "name": "recovar_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "880f599f2bd27d58460d1bc70bbd18b99899c8a176c2b30172e354f932a14999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
